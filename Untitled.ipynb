{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "import torch.nn.functional as F\n",
    "import utils.utility as utility\n",
    "from utils.logger import Logger\n",
    "from torchvision.models import resnet18\n",
    "from data.Camelyon import Camelyon\n",
    "import argparse\n",
    "from importlib import import_module\n",
    "from utils.utility import adjust_learning_rate\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "    \n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "##epoch #############################ratio \n",
    "### log_dir and data_root\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='317 MIL Framework')\n",
    "    parser.add_argument(\"--task\", type=str, default=\"Digest\",\n",
    "                        help=\"Which task to perform\",\n",
    "                        choices=[\"Digest\", \"Camelyon\"])\n",
    "    parser.add_argument('--config', type=str, default='DigestSegFull',\n",
    "                        help=\"Config file to use.\",\n",
    "                        choices=[\"DigestSegEMCAV2\", \"DigestSeg\", 'DigestSegPB',\n",
    "                                 'DigestSegTOPK', 'DigestSegFull','DigestSegRCE'])\n",
    "    parser.add_argument(\"--log_dir\", type=str,\n",
    "                        default=\"/home/ltc/1T/HisMIL/experiments/Full/2020_12_26/f4\",\n",
    "                        help=\"The experiment log directory\")\n",
    "    parser.add_argument(\"--data_root\", \"-d\", type=str,\n",
    "                        default=\"/home/ltc/Phase2/5_folder/4\",\n",
    "                        help=\"root directory of data used\")\n",
    "    parser.add_argument(\"--resume\", type=int, default=-1, help=\"Resume epoch\")\n",
    "\n",
    "    parser.add_argument(\"--backbone\", type=str, default='res18',\n",
    "                        help=\"which backbone to use.\")\n",
    "    parser.add_argument(\"--pretrained\", action=\"store_true\", default=False,\n",
    "                        help=\"Whether to use weighted BCE loss\")\n",
    "\n",
    "    parser.add_argument('-lr', type=float, default=1e-3, help=\"Learning rate\")\n",
    "    parser.add_argument(\"--epochs\", \"-e\", type=int, default=50,\n",
    "                        help=\"How many epochs to train\")\n",
    "    parser.add_argument('--cos', action='store_true', default=True,\n",
    "                      help='use cosine lr schedule')\n",
    "    parser.add_argument('--schedule', default=[120, 160], nargs='*', type=int,\n",
    "                        help='learning rate schedule (when to drop lr by 10x)')\n",
    "    #choose loss\n",
    "    # parser.add_argument(\"--rce\", action=\"store_true\", default=False, help=\"Whether to use weighted BCE loss\")\n",
    "    #Calibration loss\n",
    "    parser.add_argument(\"--stop_epoch\", type=int, default=-1, help=\"stop\")\n",
    "    parser.add_argument(\"--ignore_thres\", type=float, default=0.95, help=\"ignore\")\n",
    "    #one-stage or two stage training\n",
    "    parser.add_argument(\"--database\", action=\"store_true\", default=False, help=\"Using database\")\n",
    "    parser.add_argument('--workers', default=8, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 32)')\n",
    "    parser.add_argument(\"--load\", type=int, default=-1, help=\"the epoch to be loaded\")\n",
    "    parser.add_argument(\"--load_path\", type=str,\n",
    "                        default=\"/home/tclin/1T/Experiment/move/Baseline/f3\",\n",
    "                        help=\"The load directory\")\n",
    "    #EM\n",
    "    parser.add_argument(\"--mmt\", type=float, default=0.9, help=\"mmt\")\n",
    "    parser.add_argument(\"--noisy\", action=\"store_true\", default=False, help=\"Noisy bag pos ratio\")\n",
    "\n",
    "    # ssl\n",
    "    parser.add_argument(\"--ssl\", action=\"store_true\", default=False, help=\"Self supervised learning\")\n",
    "    parser.add_argument(\"--camelyon\", action=\"store_true\", default=False, help=\"Training on camelyon\")\n",
    "    parser.add_argument(\"--pickle\", action=\"store_true\", default=False, help=\"Using pickle\")\n",
    "    args = parser.parse_args(['-lr', '1e-3'])\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Warning: not implemented network loading, return default things\n",
      "\n",
      "Warning: not implemented network loading, return default things\n",
      "\n",
      "Warning: not implemented optimizing loading, return default things\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##epoch #############################ratio \n",
    "### log_dir and data_root\n",
    "\n",
    "def eval_(self, gs, trainset):\n",
    "    # self.backbone = self.logger.load_backbone_fromold(self.backbone, global_step=gs)\n",
    "    # self.clsnet = self.logger.load_clsnet_fromold(self.clsnet, global_step=gs)\n",
    "    self.backbone = self.logger.load_backbone(self.backbone, global_step=gs)\n",
    "#     self.clsnet = self.logger.load_clsnet(self.clsnet, global_step=gs)\n",
    "    self.backbone.eval()\n",
    "#     self.clsnet.eval()\n",
    "    val_loader = DataLoader(trainset, 256, shuffle=True, num_workers=4)\n",
    "#     confoundSet = torch.randn([trainset.__len__(), 514])\n",
    "    bag_idx_list = []\n",
    "    inner_idx_list = []\n",
    "    feature_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (imgs, instance_labels, bag_index, inner_index, nodule_ratios, real_ins_labels) in enumerate(\n",
    "                tqdm(val_loader, ascii=True, ncols=60)):\n",
    "            instance_preds = self.backbone(imgs.to(self.device))\n",
    "            feature_list.append(instance_preds)\n",
    "            bag_idx_list.append(bag_index)\n",
    "            inner_idx_list.append(inner_index)\n",
    "            \n",
    "    return feature_list, bag_idx_list, inner_idx_list\n",
    "\n",
    " #############################ratio \n",
    "### log_dir ## data_root ##epoch\n",
    "args = parse_args()\n",
    "if args.task == 'Digest':\n",
    "    configs = getattr(import_module('configs.'+'DigestSeg'), 'Config')(args)\n",
    "elif args.task == 'Camelyon':\n",
    "    configs = getattr(import_module('configs.' + 'Camelyon'), 'Config')(args)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "# configs.logger.init_backup(configs)\n",
    "trainer = configs.trainer\n",
    "tester = configs.tester\n",
    "trainer.eval = eval_\n",
    "epoch=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Resuming net of epoch /home/ltc/1T/HisMIL/experiments/Full/2020_12_26/f4/ckp/net.ckpt50.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                               | 0/138 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################| 138/138 [02:33<00:00,  1.16it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_list, bag_idx_list, inner_idx_list = trainer.eval(trainer, epoch, configs.valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.cat(feature_list)\n",
    "bag_indexs = torch.cat(bag_idx_list).unsqueeze(-1).float().cuda()\n",
    "inner_indexs = torch.cat(inner_idx_list).unsqueeze(-1).float().cuda()\n",
    "confounderSet = torch.cat((features, bag_indexs, inner_indexs),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "confounder = np.array(confounderSet.cpu())\n",
    "np.save(\"/home/ltc/1T/HisMIL/experiments/Full/2020_12_26/f4/conf.npy\", confounder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagnums = confounder[:,-2:-1].max()\n",
    "bagnums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = np.ones([int(bagnums)])/bagnums\n",
    "np.save(\"/home/ltc/1T/HisMIL/experiments/Full/2020_12_26/f4/prior.npy\", prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(527., device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confounderSet[:, -2:-1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset=configs.valset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['root', 'class_path_list', 'ins_transform', 'label_transform', 'pos_ins_threshold', 'use_clear_pos_ratios', 'bag_names', 'bag_paths', 'bag_labels', 'bag_lengths', 'bag_pos_ratios', 'real_labels_in_bags', 'pos_masks_ratios_in_bags', 'instance_labels', 'instance_infos', 'instance_real_labels', 'instance_pos_masks_ratios', 'instance_paths', 'instance_c_x', 'instance_c_y', 'instance_in_which_bag', 'instance_in_where', 'cls_label_dict', 'mean_ratios', 'min_ratios', 'database', 'ssl', 'ssl_transform', 'tmp_instance_paths', 'tmp_instance_in_which_bag', 'tmp_instance_in_where', 'tmp_instance_labels', 'tmp_instance_real_labels'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(trainset).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35187"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1859,  0.1367],\n",
       "        [-0.3012,  1.4769],\n",
       "        [ 0.1561,  0.3997],\n",
       "        [ 0.6028,  2.2155],\n",
       "        [ 0.1722,  1.1929],\n",
       "        [ 0.5240,  1.9096]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tmp = torch.randn([6,2])\n",
    "x_tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1859,  0.1367],\n",
       "         [-0.3012,  1.4769]]), tensor([[0.1561, 0.3997],\n",
       "         [0.6028, 2.2155],\n",
       "         [0.1722, 1.1929]]), tensor([[0.5240, 1.9096]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tmp.split([2,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
